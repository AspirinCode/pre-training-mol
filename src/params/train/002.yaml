note: 'RAdam lr=1e-4 from pre-train all'

module_params:
  optim: radam
  lr: 1e-4
  weight_decay: 1e-4
  batch_size: 32
  ema_decay: 0.9999
  ema_eval_freq: 1
  fold: 0
  n_splits: 4
  seed: 1
  pretrained_ckpt_path: ../experiments/mol2/1595814716/checkpoints/last.ckpt

trainer_params:
  epochs: 1000
  gpus: [0]
  num_tpu_cores: null
  use_16bit: false
